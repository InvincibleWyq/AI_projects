{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from IPython import display\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = lambda x, *args, **kwargs: x.numel(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        self.start()\n",
    "    def start(self):\n",
    "        self.tik = time.time()\n",
    "    def stop(self):\n",
    "        self.times.append(time.time() - self.tik)\n",
    "        return self.times[-1]\n",
    "    def sum(self):\n",
    "        return sum(self.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
    "    axes.set_xlabel(xlabel)\n",
    "    axes.set_ylabel(ylabel)\n",
    "    axes.set_xscale(xscale)\n",
    "    axes.set_yscale(yscale)\n",
    "    axes.set_xlim(xlim)\n",
    "    axes.set_ylim(ylim)\n",
    "    if legend:\n",
    "        axes.legend(legend)\n",
    "    axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animator:\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        \"\"\"Defined in :numref:`sec_softmax_scratch`\"\"\"\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes, ]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: set_axes(self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # Set the model to evaluation mode\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # Required for BERT Fine-tuning (to be covered later)\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), size(y))\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sum of training loss, sum of training accuracy, no. of examples\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()            \n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            print(X)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialExpressionDataset(Dataset):\n",
    "    def __init__(self, csv_path, train=True, readtensor=False, transform=None): #readtensor=True表示跳过前处理，直接读tensor\n",
    "        if not readtensor:        \n",
    "            data = pd.read_csv(csv_path)\n",
    "            if train:            \n",
    "                data = data[data.Usage=='Training']\n",
    "                data = data.reset_index(drop=True)\n",
    "            else:\n",
    "                data = data[data.Usage=='Test']\n",
    "                data = data.reset_index(drop=True)\n",
    "            self.Xlst = []\n",
    "            self.ylst = []\n",
    "            self.L = len(data)\n",
    "            for i in range(self.L):\n",
    "                xlst = data.loc[i].pixels.split()        \n",
    "                xlst = [int(x) for x in xlst]\n",
    "                X = np.array(xlst).reshape([1,48,48])\n",
    "                y = data.loc[i].emotion\n",
    "                self.Xlst.append(X)\n",
    "                self.ylst.append(y)            \n",
    "            self.Xlst = torch.tensor(self.Xlst,dtype=torch.float32)\n",
    "            self.ylst = torch.tensor(self.ylst,dtype=torch.int64)\n",
    "            if train:\n",
    "                torch.save(self.Xlst, '../data/train_data_Xlst.pt')\n",
    "                torch.save(self.ylst, '../data/train_data_ylst.pt')\n",
    "            else:\n",
    "                torch.save(self.Xlst, '../data/test_data_Xlst.pt')\n",
    "                torch.save(self.ylst, '../data/test_data_ylst.pt')                    \n",
    "        else:\n",
    "            if train:\n",
    "                self.Xlst=torch.load('../data/train_data_Xlst.pt')\n",
    "                self.ylst=torch.load('../data/train_data_ylst.pt')\n",
    "                self.L = len(self.ylst)\n",
    "            else:\n",
    "                self.Xlst=torch.load('../data/test_data_Xlst.pt')\n",
    "                self.ylst=torch.load('../data/test_data_ylst.pt')\n",
    "                self.L = len(self.ylst)\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.L\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = (self.Xlst[idx], self.ylst[idx])\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = FacialExpressionDataset('../data/data.csv', train=True, readtensor=True)\n",
    "test_data = FacialExpressionDataset('../data/data.csv', train=False, readtensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeNet\n",
    "class Reshape(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, 1, 48, 48)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(16*9*9, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape:\t torch.Size([4, 6, 44, 44])\n",
      "BatchNorm2d output shape:\t torch.Size([4, 6, 44, 44])\n",
      "Sigmoid output shape:\t torch.Size([4, 6, 44, 44])\n",
      "MaxPool2d output shape:\t torch.Size([4, 6, 22, 22])\n",
      "Conv2d output shape:\t torch.Size([4, 16, 18, 18])\n",
      "BatchNorm2d output shape:\t torch.Size([4, 16, 18, 18])\n",
      "Sigmoid output shape:\t torch.Size([4, 16, 18, 18])\n",
      "MaxPool2d output shape:\t torch.Size([4, 16, 9, 9])\n",
      "Flatten output shape:\t torch.Size([4, 1296])\n",
      "Linear output shape:\t torch.Size([4, 120])\n",
      "BatchNorm1d output shape:\t torch.Size([4, 120])\n",
      "Sigmoid output shape:\t torch.Size([4, 120])\n",
      "Linear output shape:\t torch.Size([4, 84])\n",
      "BatchNorm1d output shape:\t torch.Size([4, 84])\n",
      "Sigmoid output shape:\t torch.Size([4, 84])\n",
      "Linear output shape:\t torch.Size([4, 7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(4, 1, 48, 48))\n",
    "for blk in net:\n",
    "    X = blk(X)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "origin_pos": 33,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.620, train acc 0.378, test acc 0.383\n",
      "2710.9 examples/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs, batch_size = 0.0005, 20, 64\n",
    "train_iter = DataLoader(train_data, batch_size, shuffle=True, num_workers=0)\n",
    "test_iter = DataLoader(test_data, batch_size, shuffle=False, num_workers=0)\n",
    "train(net, train_iter, test_iter, num_epochs, lr, torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
